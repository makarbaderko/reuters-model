{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982, 2246)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "x_train = vectorize_sequences(train_data)\n",
    "X_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I method\n",
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1\n",
    "    return results\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)\n",
    "#II method\n",
    "from keras.utils.np_utils import to_categorical\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 10,  1, ...,  3,  3, 24])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model construction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model compilation and training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 3s 357us/step - loss: 2.5729 - accuracy: 0.4846 - val_loss: 1.6973 - val_accuracy: 0.6710\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 164us/step - loss: 1.3695 - accuracy: 0.7195 - val_loss: 1.2853 - val_accuracy: 0.7150\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 119us/step - loss: 1.0144 - accuracy: 0.7878 - val_loss: 1.1011 - val_accuracy: 0.7640\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 117us/step - loss: 0.7987 - accuracy: 0.8311 - val_loss: 1.0002 - val_accuracy: 0.7930\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 116us/step - loss: 0.6303 - accuracy: 0.8688 - val_loss: 0.9502 - val_accuracy: 0.8060\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 0.5039 - accuracy: 0.8938 - val_loss: 0.8985 - val_accuracy: 0.8190\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 117us/step - loss: 0.4044 - accuracy: 0.9137 - val_loss: 0.8815 - val_accuracy: 0.8200\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 134us/step - loss: 0.3302 - accuracy: 0.9295 - val_loss: 0.8892 - val_accuracy: 0.8170\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 131us/step - loss: 0.2744 - accuracy: 0.9375 - val_loss: 0.8756 - val_accuracy: 0.8220\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 120us/step - loss: 0.2289 - accuracy: 0.9451 - val_loss: 0.9026 - val_accuracy: 0.8150\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 130us/step - loss: 0.2015 - accuracy: 0.9503 - val_loss: 0.8898 - val_accuracy: 0.8210\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 119us/step - loss: 0.1774 - accuracy: 0.9518 - val_loss: 0.9684 - val_accuracy: 0.8130\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 0.1560 - accuracy: 0.9528 - val_loss: 0.9505 - val_accuracy: 0.8190\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 117us/step - loss: 0.1501 - accuracy: 0.9534 - val_loss: 0.9750 - val_accuracy: 0.8140\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 0.1377 - accuracy: 0.9560 - val_loss: 1.0713 - val_accuracy: 0.7760\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 0.1317 - accuracy: 0.9549 - val_loss: 0.9843 - val_accuracy: 0.8200\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 0.1232 - accuracy: 0.9574 - val_loss: 1.0666 - val_accuracy: 0.7970\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 0.1186 - accuracy: 0.9559 - val_loss: 1.1174 - val_accuracy: 0.7870\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 132us/step - loss: 0.1158 - accuracy: 0.9578 - val_loss: 1.0193 - val_accuracy: 0.8080\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 128us/step - loss: 0.1094 - accuracy: 0.9594 - val_loss: 1.1102 - val_accuracy: 0.7980\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting graphs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss and val loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss)+1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label=\"Validation loss\")\n",
    "plt.title(\"Training and val\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
